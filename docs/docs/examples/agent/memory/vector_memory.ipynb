{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9cfc1b0-f28a-43ee-8242-90cfdb49fec2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Vector Memory\n",
    "\n",
    "The vector memory module uses vector search (backed by a vector db) to retrieve relevant conversation items given a user input.\n",
    "\n",
    "This notebook shows you how to use the `VectorMemory` class. We show you how to use its individual functions, as well as how to plug it into an agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d29a822-727d-4a87-aa7f-e3091a311d5f",
   "metadata": {},
   "source": [
    "### Initialize and Experiment with Memory Module\n",
    "\n",
    "Here we initialize a raw memory module and demonstrate its functions - to put and retrieve from ChatMessage objects.\n",
    "\n",
    "- Note that `retriever_kwargs` is the same args you'd specify on the `VectorIndexRetriever` or from `index.as_retriever(..)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fefa31-4c6c-4ae4-9957-ea73781ecc21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.memory import VectorMemory\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "\n",
    "vector_memory = VectorMemory.from_defaults(\n",
    "    vector_store=None, # leave as None to use default in-memory vector store\n",
    "    embed_model=OpenAIEmbedding(),\n",
    "    retriever_kwargs={\"similarity_top_k\": 1} \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8073c255-a35e-432d-a917-12dafaf377e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "msgs = [\n",
    "    ChatMessage.from_str(\"Jerry likes juice.\", \"user\"),\n",
    "    ChatMessage.from_str(\"Bob likes burgers.\", \"user\"),\n",
    "    ChatMessage.from_str(\"Alice likes apples.\", \"user\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44017c1-129a-4864-a070-c00ca6d6cf0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load into memory\n",
    "for m in msgs:\n",
    "    vector_memory.put(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa077b6e-6477-406a-8d52-d8e375daae6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory returning messages: [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='This is a set of relevant messages retrieved from longer-term history: ', additional_kwargs={}), ChatMessage(role=<MessageRole.USER: 'user'>, content='Jerry likes juice.', additional_kwargs={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='This is a set of relevant messages retrieved from longer-term history: ', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.USER: 'user'>, content='Jerry likes juice.', additional_kwargs={})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve from memory\n",
    "msgs = vector_memory.get(\"What does Jerry like?\")\n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4baa16-55d1-418c-ac7f-a8f30252e6c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_memory.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f17529-bd4a-4edb-8176-7332e48016ea",
   "metadata": {},
   "source": [
    "Note that the system message is by default returned along with the user message. You can choose to disable the system message if you'd like.\n",
    "\n",
    "Now let's try resetting and trying again. This time, we'll add an assistant message. Note that user/assistant messages are bundled by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c427d1-c157-4916-a9c2-17b3fede4f18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "msgs = [\n",
    "    ChatMessage.from_str(\"Jerry likes burgers.\", \"user\"),\n",
    "    ChatMessage.from_str(\"Bob likes apples.\", \"user\"),\n",
    "    ChatMessage.from_str(\"Indeed, Bob likes apples.\", \"assistant\"),\n",
    "    ChatMessage.from_str(\"Alice likes juice.\", \"user\")\n",
    "]\n",
    "vector_memory.set(msgs)\n",
    "vector_memory.system_message = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4402fe-f140-415b-9e07-accbde8ae2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory returning messages: [ChatMessage(role=<MessageRole.USER: 'user'>, content='Bob likes apples.', additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Indeed, Bob likes apples.', additional_kwargs={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role=<MessageRole.USER: 'user'>, content='Bob likes apples.', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Indeed, Bob likes apples.', additional_kwargs={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = vector_memory.get(\"What does Bob like?\")\n",
    "msgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3935b6a6-e1d2-4948-bbfc-af826257c2df",
   "metadata": {},
   "source": [
    "## Plug Memory Module into Agent\n",
    "\n",
    "Let's now try plugging this memory module into an agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d1374b3-346e-4a76-8587-7f2e52f64ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_memory.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9facf7ad-0f92-4f02-8214-9dc81891e8a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96cfecd0-6ca3-4353-b3a6-88b526f126c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def mystery(a: int, b: int) -> int:\n",
    "    \"\"\"Mystery function on two numbers\"\"\"\n",
    "    return a**2 - b**2\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9908320-b027-4d1a-8bed-5ac58187e0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [multiply_tool, mystery_tool], llm=llm, verbose=True\n",
    ")\n",
    "agent = agent_worker.as_agent(memory=vector_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4459c5f2-6c36-4aa4-8fde-e478d51d831d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is the mystery function on 5 and 6?\n",
      "Memory returning messages: []\n",
      "=== Calling Function ===\n",
      "Calling function: mystery with args: {\"a\": 5, \"b\": 6}\n",
      "=== Function Output ===\n",
      "-11\n",
      "Memory returning messages: []\n",
      "=== LLM Response ===\n",
      "The mystery function on 5 and 6 returns -11.\n",
      "assistant: The mystery function on 5 and 6 returns -11.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What is the mystery function on 5 and 6?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "507f87e0-8c4e-4abd-99bc-5f62fd82a384",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory returning messages: [ChatMessage(role=<MessageRole.USER: 'user'>, content='What is the mystery function on 5 and 6?', additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [{'id': 'call_ZivV7lGHvE4qHW7H7DUKFSuy', 'function': {'arguments': '{\\n  \"a\": 5,\\n  \"b\": 6\\n}', 'name': 'mystery'}, 'type': 'function'}]}), ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='-11', additional_kwargs={'name': 'mystery', 'tool_call_id': 'call_ZivV7lGHvE4qHW7H7DUKFSuy'}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='The mystery function on 5 and 6 returns -11.', additional_kwargs={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role=<MessageRole.USER: 'user'>, content='What is the mystery function on 5 and 6?', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [{'id': 'call_ZivV7lGHvE4qHW7H7DUKFSuy', 'function': {'arguments': '{\\n  \"a\": 5,\\n  \"b\": 6\\n}', 'name': 'mystery'}, 'type': 'function'}]}),\n",
       " ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='-11', additional_kwargs={'name': 'mystery', 'tool_call_id': 'call_ZivV7lGHvE4qHW7H7DUKFSuy'}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='The mystery function on 5 and 6 returns -11.', additional_kwargs={})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory.get(\"mystery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a4e517b-30e7-47de-88eb-e19e7b605cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What happens if you multiply 2 and 3?\n",
      "Memory returning messages: [ChatMessage(role=<MessageRole.USER: 'user'>, content='What is the mystery function on 5 and 6?', additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [{'id': 'call_ZivV7lGHvE4qHW7H7DUKFSuy', 'function': {'arguments': '{\\n  \"a\": 5,\\n  \"b\": 6\\n}', 'name': 'mystery'}, 'type': 'function'}]}), ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='-11', additional_kwargs={'name': 'mystery', 'tool_call_id': 'call_ZivV7lGHvE4qHW7H7DUKFSuy'}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='The mystery function on 5 and 6 returns -11.', additional_kwargs={})]\n",
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\"a\": 2, \"b\": 3}\n",
      "=== Function Output ===\n",
      "6\n",
      "Memory returning messages: [ChatMessage(role=<MessageRole.USER: 'user'>, content='What is the mystery function on 5 and 6?', additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [{'id': 'call_ZivV7lGHvE4qHW7H7DUKFSuy', 'function': {'arguments': '{\\n  \"a\": 5,\\n  \"b\": 6\\n}', 'name': 'mystery'}, 'type': 'function'}]}), ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='-11', additional_kwargs={'name': 'mystery', 'tool_call_id': 'call_ZivV7lGHvE4qHW7H7DUKFSuy'}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='The mystery function on 5 and 6 returns -11.', additional_kwargs={})]\n",
      "=== LLM Response ===\n",
      "If you multiply 2 and 3, the result is 6.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What happens if you multiply 2 and 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f84c3e66-2f13-435f-8ea1-8c51467c4dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory returning messages: [ChatMessage(role=<MessageRole.USER: 'user'>, content='What is the mystery function on 5 and 6?', additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [{'id': 'call_ZivV7lGHvE4qHW7H7DUKFSuy', 'function': {'arguments': '{\\n  \"a\": 5,\\n  \"b\": 6\\n}', 'name': 'mystery'}, 'type': 'function'}]}), ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='-11', additional_kwargs={'name': 'mystery', 'tool_call_id': 'call_ZivV7lGHvE4qHW7H7DUKFSuy'}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='The mystery function on 5 and 6 returns -11.', additional_kwargs={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role=<MessageRole.USER: 'user'>, content='What is the mystery function on 5 and 6?', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [{'id': 'call_ZivV7lGHvE4qHW7H7DUKFSuy', 'function': {'arguments': '{\\n  \"a\": 5,\\n  \"b\": 6\\n}', 'name': 'mystery'}, 'type': 'function'}]}),\n",
       " ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='-11', additional_kwargs={'name': 'mystery', 'tool_call_id': 'call_ZivV7lGHvE4qHW7H7DUKFSuy'}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='The mystery function on 5 and 6 returns -11.', additional_kwargs={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory.get(\"mystery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b6a1619-8561-4c88-ab24-84fc53c8dbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: If you multiply 2 and 3, the result is 6.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12147c5a-7587-4b15-8ce2-59149b9a647c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What if you multiply the output of the mystery operation from the previous message, by 5?\n",
      "Memory returning messages: [ChatMessage(role=<MessageRole.USER: 'user'>, content='What happens if you multiply 2 and 3?', additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [{'id': 'call_8LH43Pzh6hW2kJQKkCiAwmyX', 'function': {'arguments': '{\\n  \"a\": 2,\\n  \"b\": 3\\n}', 'name': 'multiply'}, 'type': 'function'}]}), ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='6', additional_kwargs={'name': 'multiply', 'tool_call_id': 'call_8LH43Pzh6hW2kJQKkCiAwmyX'}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='If you multiply 2 and 3, the result is 6.', additional_kwargs={})]\n",
      "=== Calling Function ===\n",
      "Calling function: mystery with args: {\"a\": 2, \"b\": 3}\n",
      "=== Function Output ===\n",
      "-5\n",
      "Memory returning messages: [ChatMessage(role=<MessageRole.USER: 'user'>, content='What happens if you multiply 2 and 3?', additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [{'id': 'call_8LH43Pzh6hW2kJQKkCiAwmyX', 'function': {'arguments': '{\\n  \"a\": 2,\\n  \"b\": 3\\n}', 'name': 'multiply'}, 'type': 'function'}]}), ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='6', additional_kwargs={'name': 'multiply', 'tool_call_id': 'call_8LH43Pzh6hW2kJQKkCiAwmyX'}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='If you multiply 2 and 3, the result is 6.', additional_kwargs={})]\n",
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\"a\": -5, \"b\": 5}\n",
      "=== Function Output ===\n",
      "-25\n",
      "Memory returning messages: [ChatMessage(role=<MessageRole.USER: 'user'>, content='What happens if you multiply 2 and 3?', additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [{'id': 'call_8LH43Pzh6hW2kJQKkCiAwmyX', 'function': {'arguments': '{\\n  \"a\": 2,\\n  \"b\": 3\\n}', 'name': 'multiply'}, 'type': 'function'}]}), ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='6', additional_kwargs={'name': 'multiply', 'tool_call_id': 'call_8LH43Pzh6hW2kJQKkCiAwmyX'}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='If you multiply 2 and 3, the result is 6.', additional_kwargs={})]\n",
      "=== LLM Response ===\n",
      "If you multiply the output of the mystery operation from the previous message, which is -5, by 5, the result is -25.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc67719-2150-4855-99d4-2a5761cb686f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v3",
   "language": "python",
   "name": "llama_index_v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
