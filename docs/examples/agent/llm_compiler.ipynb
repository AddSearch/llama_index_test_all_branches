{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2cf3ee9-d4dd-44d1-a529-6e92d9f8e023",
   "metadata": {},
   "source": [
    "# LLM Compiler Agent Cookbook\n",
    "\n",
    "**NOTE**: Full credits to the [source repo for LLMCompiler](https://github.com/SqueezeAILab/LLMCompiler). A lot of our implementation was lifted from this repo (and adapted with LlamaIndex modules).\n",
    "\n",
    "In this cookbook, we show how to use our LLMCompiler agent implementation for various settings. This includes using some simple function tools to do math, but also to answer multi-part queries for more advanced RAG use cases.\n",
    "\n",
    "We see that the LLMCompilerAgent is capable of parallel function calling, giving results much more quickly than sequential execution through ReAct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b9616-fbd3-4686-9ce3-2893bdfad2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 To view the Phoenix app in your browser, visit http://127.0.0.1:6006/\n",
      "📺 To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "📖 For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "# Phoenix can display in real time the traces automatically\n",
    "# collected from your LlamaIndex application.\n",
    "import phoenix as px\n",
    "\n",
    "# Look for a URL in the output to open the App in a browser.\n",
    "px.launch_app()\n",
    "# The App is initially empty, but as you proceed with the steps below,\n",
    "# traces will appear automatically as your LlamaIndex application runs.\n",
    "\n",
    "import llama_index\n",
    "\n",
    "llama_index.set_global_handler(\"arize_phoenix\")\n",
    "\n",
    "# Run all of your LlamaIndex applications as usual and traces\n",
    "# will be collected and displayed in Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338345d0-0b03-44f0-b812-d98b530d047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82925e9-0c6b-4e1a-82f7-5d238cfd4bc6",
   "metadata": {},
   "source": [
    "## Test LLMCompiler Agent with Simple Functions\n",
    "\n",
    "Here we test the LLMCompilerAgent with simple math functions (add, multiply) to illustrate how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fdf3ad-0ded-4165-bdc6-870f91dc723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Sequence, List\n",
    "\n",
    "from llama_index.llms import OpenAI, ChatMessage\n",
    "from llama_index.tools import BaseTool, FunctionTool\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc38b021-97c8-4d00-8781-91ce081547c0",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13da398-bd9e-4f2e-82d2-2dbb62a3ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "\n",
    "tools = [multiply_tool, add_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77611c-5df1-488e-8856-6bc5cdb4249e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'title': 'multiply', 'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply_tool.metadata.fn_schema_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce60c7-9625-42a2-87d6-a8fe7854a4ca",
   "metadata": {},
   "source": [
    "### Setup LLMCompiler Agent\n",
    "\n",
    "We import the `LLMCompilerAgentWorker` and combine it with the `AgentRunner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19c91f-af44-4032-a9c5-50512f3c66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import AgentRunner\n",
    "from llama_index.agent.llm_compiler.step import LLMCompilerAgentWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b3fa8a-647f-4268-aac2-4816fcfbdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a6043-4824-4a12-9de7-fbfe15c4e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_manager = llm.callback_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c14e9bb-b401-414e-916e-4c575b26b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = LLMCompilerAgentWorker.from_tools(\n",
    "    tools, llm=llm, verbose=True, callback_manager=callback_manager\n",
    ")\n",
    "agent = AgentRunner(agent_worker, callback_manager=callback_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f2da7b-e611-4441-ab0e-22b8748ec658",
   "metadata": {},
   "source": [
    "### Test out some Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0980a07-d2f5-434a-b9e9-80deabc0d1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 7964650f-4a30-4de9-a560-d2658692ce52 for task 3fcacae8-9d51-498a-9c14-597df7834761.\n",
      "> Step count: 0\n",
      "\u001b[1;3;38;5;200m> Plan: 1. multiply(121, 3)\n",
      "2. add($1, 42)\n",
      "3. join()<END_OF_PLAN>\n",
      "\u001b[0m\u001b[1;3;34mRan task: multiply. Observation: 363\n",
      "\u001b[0m\u001b[1;3;34mRan task: add. Observation: 405\n",
      "\u001b[0m\u001b[1;3;34mRan task: join. Observation: None\n",
      "\u001b[0m\u001b[1;3;38;5;200m> Thought: The result of the operation is 405.\n",
      "\u001b[0m\u001b[1;3;38;5;200m> Answer: 405\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What is (121 * 3) + 42?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe5e1f-4929-4f47-9af2-1da8faebe638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='405', sources=[], source_nodes=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e836cb-f481-4033-afca-211a52ef0665",
   "metadata": {},
   "source": [
    "## Try out LLMCompiler for RAG\n",
    "\n",
    "Now let's try out the LLMCompiler for RAG use cases. Specifically, we load a dataset of Wikipedia articles about various cities and ask questions over them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975c5d36-6d80-4004-a565-15351b7ac702",
   "metadata": {},
   "source": [
    "### Setup Data\n",
    "\n",
    "We use our `WikipediaReader` to load data for various cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50dccdc-491e-4ff2-8657-5dfea6fab284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers import WikipediaReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2647c3be-1637-4b88-ae76-bb513f7e9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_titles = [\n",
    "    \"Toronto\",\n",
    "    \"Seattle\",\n",
    "    \"Chicago\",\n",
    "    \"Boston\",\n",
    "    \"Houston\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb7add-aa6c-4f47-8d8c-6a6d222adc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_docs = {}\n",
    "reader = WikipediaReader()\n",
    "for wiki_title in wiki_titles:\n",
    "    docs = reader.load_data(pages=[wiki_title])\n",
    "    city_docs[wiki_title] = docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af02a14-0d58-4570-93c5-78e1c87c8c72",
   "metadata": {},
   "source": [
    "### Setup LLM + Service Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6425ad0e-2f8e-4101-8730-387f4aab8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-4\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a52155-1790-44e6-b6be-14964b0b25f1",
   "metadata": {},
   "source": [
    "### Define Toolset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91324b15-9f98-4f52-a832-2eadc76b73c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import load_index_from_storage, StorageContext\n",
    "from llama_index.node_parser import SentenceSplitter\n",
    "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index import VectorStoreIndex\n",
    "import os\n",
    "\n",
    "node_parser = SentenceSplitter()\n",
    "\n",
    "# Build agents dictionary\n",
    "query_engine_tools = []\n",
    "\n",
    "for idx, wiki_title in enumerate(wiki_titles):\n",
    "    nodes = node_parser.get_nodes_from_documents(city_docs[wiki_title])\n",
    "\n",
    "    if not os.path.exists(f\"./data/{wiki_title}\"):\n",
    "        # build vector index\n",
    "        vector_index = VectorStoreIndex(nodes, service_context=service_context)\n",
    "        vector_index.storage_context.persist(\n",
    "            persist_dir=f\"./data/{wiki_title}\"\n",
    "        )\n",
    "    else:\n",
    "        vector_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=f\"./data/{wiki_title}\"),\n",
    "            service_context=service_context,\n",
    "        )\n",
    "    # define query engines\n",
    "    vector_query_engine = vector_index.as_query_engine()\n",
    "\n",
    "    # define tools\n",
    "    query_engine_tools.append(\n",
    "        QueryEngineTool(\n",
    "            query_engine=vector_query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=f\"vector_tool_{wiki_title}\",\n",
    "                description=(\n",
    "                    \"Useful for questions related to specific aspects of\"\n",
    "                    f\" {wiki_title} (e.g. the history, arts and culture,\"\n",
    "                    \" sports, demographics, or more).\"\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29750eb8-b117-4777-b228-32e8becf662c",
   "metadata": {},
   "source": [
    "### Setup LLMCompilerAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde0c37b-5660-43a0-a22f-78d4521204a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import AgentRunner\n",
    "from llama_index.agent.llm_compiler.step import LLMCompilerAgentWorker\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4\")\n",
    "callback_manager = llm.callback_manager\n",
    "agent_worker = LLMCompilerAgentWorker.from_tools(\n",
    "    query_engine_tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    callback_manager=callback_manager,\n",
    ")\n",
    "agent = AgentRunner(agent_worker, callback_manager=callback_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2e41c1-3c68-4cc0-85f1-94eb21746bac",
   "metadata": {},
   "source": [
    "### Test out Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54484552-e53f-4548-8719-8c188179b596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 40eddf6d-4981-4b25-92b6-1a0e8c04455e for task 27aeb88c-5af7-455f-91ea-0e90a13f1618.\n",
      "> Step count: 0\n",
      "\u001b[1;3;38;5;200m> Plan: 1. vector_tool_Houston('demographics')\n",
      "2. vector_tool_Chicago('demographics')\n",
      "3. join()<END_OF_PLAN>\n",
      "\u001b[0m\u001b[1;3;34mRan task: vector_tool_Chicago. Observation: Chicago has a diverse demographic makeup. The city experienced rapid growth in its early years, with the population reaching over 1 million by 1890. By the end of the 19th century, Chicago was the fifth-largest city in the world. The city saw waves of immigrants from various parts of the world, including Ireland, Southern, Central and Eastern Europe, and Africa. The city's black population doubled between 1910 and 1920, and again between 1920 and 1930. As of July 2019, the largest racial or ethnic group in Chicago is non-Hispanic White at 32.8% of the population, followed by Blacks at 30.1% and the Hispanic population at 29.0%. The city also has the third-largest LGBT population in the United States. The city's population declined in the latter half of the 20th century, but has seen a rise in the 2000 and 2020 censuses.\n",
      "\u001b[0m\u001b[1;3;34mRan task: vector_tool_Houston. Observation: As of 2020, Boston had an estimated population of 691,531 residents living in 266,724 households, marking a 12% increase from 2010. The city is the third-most densely populated large U.S. city with over half a million residents. The population is diverse, with 21.9% under the age of 19, 14.3% from 20 to 24, 33.2% from 25 to 44, 20.4% from 45 to 64, and 10.1% who were 65 years or older. The median age was 30.8 years. The gender ratio was 92.0 males for every 100 females, and 89.9 males for every 100 females age 18 and over. The median household income was $51,739, and the median income for a family was $61,035. The city has a significant racial wealth gap, with White Bostonians having a median net worth of $247,500 compared to $8 for non-immigrant Black residents and $0 for Dominican immigrant residents. The city has experienced significant gentrification in the 21st century. African-Americans comprise 22% of the city's population, followed by people of Irish descent (15.8%), Italians (8.3%), and people of West Indian and Caribbean ancestry (over 15%).\n",
      "\u001b[0m\u001b[1;3;34mRan task: join. Observation: None\n",
      "\u001b[0m\u001b[1;3;38;5;200m> Thought: Houston has a population of 691,531 with a median age of 30.8 years and a median household income of $51,739. The city is diverse with African-Americans comprising 22% of the population. On the other hand, Chicago has a diverse demographic makeup with the largest racial or ethnic group being non-Hispanic White at 32.8% of the population, followed by Blacks at 30.1% and the Hispanic population at 29.0%. The city has the third-largest LGBT population in the United States.\n",
      "\u001b[0m\u001b[1;3;38;5;200m> Answer: Houston has a population of 691,531 with a median age of 30.8 years and a median household income of $51,739. The city is diverse with African-Americans comprising 22% of the population. On the other hand, Chicago has a diverse demographic makeup with the largest racial or ethnic group being non-Hispanic White at 32.8% of the population, followed by Blacks at 30.1% and the Hispanic population at 29.0%. The city has the third-largest LGBT population in the United States.\n",
      "\u001b[0mHouston has a population of 691,531 with a median age of 30.8 years and a median household income of $51,739. The city is diverse with African-Americans comprising 22% of the population. On the other hand, Chicago has a diverse demographic makeup with the largest racial or ethnic group being non-Hispanic White at 32.8% of the population, followed by Blacks at 30.1% and the Hispanic population at 29.0%. The city has the third-largest LGBT population in the United States.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Tell me about the demographics of Houston, and compare that with the demographics of Chicago?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0c219-ce9b-435c-86e1-85f5aaf3afe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 92534a45-c8b1-4330-8c50-07030cee9bef for task a58e6fa0-e463-4832-970e-559d86318467.\n",
      "> Step count: 0\n",
      "\u001b[1;3;38;5;200m> Plan: 1. vector_tool_Chicago('climate during wintertime')\n",
      "2. vector_tool_Seattle('climate during wintertime')\n",
      "3. join()<END_OF_PLAN>\n",
      "\u001b[0m\u001b[1;3;34mRan task: vector_tool_Seattle. Observation: During wintertime, Seattle experiences cool, wet conditions. Extreme cold temperatures, below about 15 °F or -9 °C, are rare due to the moderating influence of the adjacent Puget Sound, the greater Pacific Ocean, and Lake Washington. The city is often cloudy due to frequent storms and lows moving in from the Pacific Ocean. It has many \"rain days\", with at least 0.01 inches of precipitation falling on an average of 150 days per year. However, the rainfall is often a light drizzle spread over many days.\n",
      "\u001b[0m\u001b[1;3;34mRan task: vector_tool_Chicago. Observation: During wintertime, the city experiences relatively cold and snowy conditions. Blizzards can occur, as they did in winter 2011. The normal winter high from December through March is about 36 °F (2 °C). January and February are the coldest months. A polar vortex in January 2019 nearly broke the city's cold record of −27 °F (−33 °C), which was set on January 20, 1985. Measurable snowfall can continue through the first or second week of April. The city's proximity to Lake Michigan tends to keep the lakefront somewhat cooler in summer and less brutally cold in winter than inland parts of the city and suburbs away from the lake. Northeast winds from wintertime cyclones departing south of the region sometimes bring the city lake-effect snow.\n",
      "\u001b[0m\u001b[1;3;34mRan task: join. Observation: None\n",
      "\u001b[0m\u001b[1;3;38;5;200m> Thought: Comparing the two climates, Seattle has milder and wetter winters, while Chicago has colder and snowier winters. The preference between the two depends on personal preference.\n",
      "\u001b[0m\u001b[1;3;38;5;200m> Answer: Preference depends on personal liking\n",
      "\u001b[0mPreference depends on personal liking\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Is the climate of Chicago or Seattle better during the wintertime?\"\n",
    ")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
