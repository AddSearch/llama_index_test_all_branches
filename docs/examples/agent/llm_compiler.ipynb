{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2cf3ee9-d4dd-44d1-a529-6e92d9f8e023",
   "metadata": {},
   "source": [
    "# LLM Compiler Agent\n",
    "\n",
    "Full credits to the [source repo for LLMCompiler](https://github.com/SqueezeAILab/LLMCompiler).\n",
    "\n",
    "A lot of our implementation was lifted from this repo (and adapted with LlamaIndex modules).\n",
    "\n",
    "LLM Compiler agent notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6b9616-fbd3-4686-9ce3-2893bdfad2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 To view the Phoenix app in your browser, visit http://127.0.0.1:6006/\n",
      "📺 To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "📖 For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "# Phoenix can display in real time the traces automatically\n",
    "# collected from your LlamaIndex application.\n",
    "import phoenix as px\n",
    "\n",
    "# Look for a URL in the output to open the App in a browser.\n",
    "px.launch_app()\n",
    "# The App is initially empty, but as you proceed with the steps below,\n",
    "# traces will appear automatically as your LlamaIndex application runs.\n",
    "\n",
    "import llama_index\n",
    "\n",
    "llama_index.set_global_handler(\"arize_phoenix\")\n",
    "\n",
    "# Run all of your LlamaIndex applications as usual and traces\n",
    "# will be collected and displayed in Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338345d0-0b03-44f0-b812-d98b530d047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6fdf3ad-0ded-4165-bdc6-870f91dc723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Sequence, List\n",
    "\n",
    "from llama_index.llms import OpenAI, ChatMessage\n",
    "from llama_index.tools import BaseTool, FunctionTool\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c13da398-bd9e-4f2e-82d2-2dbb62a3ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "\n",
    "tools = [multiply_tool, add_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd19c91f-af44-4032-a9c5-50512f3c66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import AgentRunner\n",
    "from llama_index.agent.llm_compiler.step import LLMCompilerAgentWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35b3fa8a-647f-4268-aac2-4816fcfbdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "413a6043-4824-4a12-9de7-fbfe15c4e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_manager = llm.callback_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c14e9bb-b401-414e-916e-4c575b26b5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: Given a user query, create a plan to solve it with the utmost parallelizability. Each plan should comprise an action from the following 3 types:\n",
      "1. multiply(a: int, b: int) -> int\n",
      "Multiple two integers and returns the result integer\n",
      "2. add(a: int, b: int) -> int\n",
      "Add two integers and returns the result integer\n",
      "3. join():\n",
      " - Collects and combines results from prior actions.\n",
      " - A LLM agent is called upon invoking join to either finalize the user query or wait until the plans are executed.\n",
      " - join should always be the last action in the plan, and will be called in two scenarios:\n",
      "   (a) if the answer can be determined by gathering the outputs from tasks to generate the final response.\n",
      "   (b) if the answer cannot be determined in the planning phase before you execute the plans. \n",
      "\n",
      "Guidelines:\n",
      " - Each action described above contains input/output types and description.\n",
      "    - You must strictly adhere to the input and output types for each action.\n",
      "    - The action descriptions contain the guidelines. You MUST strictly follow those guidelines when you use the actions.\n",
      " - Each action in the plan should strictly be one of the above types. Follow the Python conventions for each action.\n",
      " - Each action MUST have a unique ID, which is strictly increasing.\n",
      " - Inputs for actions can either be constants or outputs from preceding actions. In the latter case, use the format $id to denote the ID of the previous action whose output will be the input.\n",
      " - Always call join as the last action in the plan. Say '<END_OF_PLAN>' after you call join\n",
      " - Ensure the plan maximizes parallelizability.\n",
      " - Only use the provided action types. If a query cannot be addressed using these, invoke the join action for the next steps.\n",
      " - Never explain the plan with comments (e.g. #).\n",
      " - Never introduce new actions other than the ones provided.\n",
      "\n",
      "Here are some examples from other questions/toolsets.\n",
      "Example:\n",
      "Question: If cheetah was 1.3 times slower, greyhound was 1.5 times faster, and falcon was 2.3 time slower then their maximum speeds, what will be the ratio of the fastest animal to the slowest animal?\n",
      "1. search(\"cheetah\")\n",
      "2. math(\"cheetah max speed in km/h if 1.3 times slower?\", [\"$1\"]\n",
      "3. search(\"greyhound\")\n",
      "4. math(\"greyhound max speed in km/h if 1.5 times faster?\", [\"$3\"]\n",
      "5. search(\"falcon\")\n",
      "6. math(\"falcon max speed in km/h if 2.3 times slower?\", [\"$5\"]\n",
      "7. math(\"max($2, $4, $6) / min($2, $4, $6)\")\n",
      "Thought: I can answer the question now.\n",
      "8. join()<END_OF_PLAN>\n",
      "###\n",
      "\n",
      "Question: Find a movie similar to Mission Impossible, The Silence of the Lambs, American Beauty, Star Wars Episode IV - A New Hope\n",
      "Options:\n",
      "Austin Powers International Man of Mystery\n",
      "Alesha Popvich and Tugarin the Dragon\n",
      "In Cold Blood\n",
      "Rosetta\n",
      "Thought: I need to find all movies in the Question.\n",
      "1. search(\"Mission Impossible\")\n",
      "2. search(\"The Silence of the Lambs\")\n",
      "3. search(\"American Beauty\")\n",
      "4. search(\"Star Wars Episode IV - A New Hope\")\n",
      "Thought: I need to find all movies in the Options.\n",
      "5. search(Austin Powers International Man of Mystery)\n",
      "6. search(Alesha Popvich and Tugarin the Dragon)\n",
      "7. search(In Cold Blood)\n",
      "8. search(Rosetta)\n",
      "Thought: I can answer the question now.\n",
      "9. join()<END_OF_PLAN>\n",
      "###\n",
      "\n",
      "Question: Which magazine was started first Arthur's Magazine or First for Women?\n",
      "1. search(\"Arthur's Magazine\")\n",
      "2. search(\"First for Women (magazine)\")\n",
      "Thought: I can answer the question now.\n",
      "3. join()<END_OF_PLAN>\n",
      "###\n",
      "\n",
      "Question: Were Pavel Urysohn and Leonid Levin known for the same type of work?\n",
      "1. search(\"Pavel Urysohn\")\n",
      "2. search(\"Leonid Levin\")\n",
      "Thought: I can answer the question now.\n",
      "3. join()<END_OF_PLAN>\n",
      "###\n",
      "\n",
      "Question: Determine the smaller value: the depth difference in meters between the Mariana Trench and the Puerto Rico Trench, or the depth difference in meters between the South Sandwich Trench and the Sunda Trench.\n",
      "1. search('Mariana Trench')\n",
      "2. search('Puerto Rico Trench')\n",
      "3. math('absolute depth difference between Mariana and Puerto Rico Trench in meters?', ['$1', '$2'])\n",
      "4. search('South Sandwich Trench')\n",
      "5. search('Sunda Trench')\n",
      "6. math('absolute depth difference between South Sandwich and Sunda Trench in meters?', ['$4', '$5'])\n",
      "7. math('min($3, $6)')\n",
      "Thought: I can answer the question now.\n",
      "8. join()<END_OF_PLAN>\n",
      "###\n",
      "\n",
      "Question: What is the raio of the height of Mount Everest and the height of Mount Kilimanjaro?\n",
      "1. search('Mount Everest')\n",
      "2. search('Mount Kilimanjaro')\n",
      "3. math('height of Mount Everest / height of Mount Kilimanjaro', ['$1', '$2'])\n",
      "Thought: I can answer the question now.\n",
      "4. join()<END_OF_PLAN>\n",
      "###\n",
      "\n",
      "\n",
      "\n",
      "PREFIX: Given a user query, create a plan to solve it with the utmost parallelizability. Each plan should comprise an action from the following 3 types:\n",
      "1. multiply(a: int, b: int) -> int\n",
      "Multiple two integers and returns the result integer\n",
      "2. add(a: int, b: int) -> int\n",
      "Add two integers and returns the result integer\n",
      "3. join():\n",
      " - Collects and combines results from prior actions.\n",
      " - A LLM agent is called upon invoking join to either finalize the user query or wait until the plans are executed.\n",
      " - join should always be the last action in the plan, and will be called in two scenarios:\n",
      "   (a) if the answer can be determined by gathering the outputs from tasks to generate the final response.\n",
      "   (b) if the answer cannot be determined in the planning phase before you execute the plans. \n",
      "\n",
      "Guidelines:\n",
      " - Each action described above contains input/output types and description.\n",
      "    - You must strictly adhere to the input and output types for each action.\n",
      "    - The action descriptions contain the guidelines. You MUST strictly follow those guidelines when you use the actions.\n",
      " - Each action in the plan should strictly be one of the above types. Follow the Python conventions for each action.\n",
      " - Each action MUST have a unique ID, which is strictly increasing.\n",
      " - Inputs for actions can either be constants or outputs from preceding actions. In the latter case, use the format $id to denote the ID of the previous action whose output will be the input.\n",
      " - Always call join as the last action in the plan. Say '<END_OF_PLAN>' after you call join\n",
      " - Ensure the plan maximizes parallelizability.\n",
      " - Only use the provided action types. If a query cannot be addressed using these, invoke the join action for the next steps.\n",
      " - Never explain the plan with comments (e.g. #).\n",
      " - Never introduce new actions other than the ones provided.\n",
      "\n",
      " - You are given \"Previous Plan\" which is the plan that the previous agent created along with the execution results (given as Observation) of each plan and a general thought (given as Thought) about the executed results.You MUST use these information to create the next plan under \"Current Plan\".\n",
      " - When starting the Current Plan, you should start with \"Thought\" that outlines the strategy for the next plan.\n",
      " - In the Current Plan, you should NEVER repeat the actions that are already executed in the Previous Plan.\n",
      "Here are some examples from other questions/toolsets.\n",
      "Example:\n",
      "Question: If cheetah was 1.3 times slower, greyhound was 1.5 times faster, and falcon was 2.3 time slower then their maximum speeds, what will be the ratio of the fastest animal to the slowest animal?\n",
      "1. search(\"cheetah\")\n",
      "2. math(\"cheetah max speed in km/h if 1.3 times slower?\", [\"$1\"]\n",
      "3. search(\"greyhound\")\n",
      "4. math(\"greyhound max speed in km/h if 1.5 times faster?\", [\"$3\"]\n",
      "5. search(\"falcon\")\n",
      "6. math(\"falcon max speed in km/h if 2.3 times slower?\", [\"$5\"]\n",
      "7. math(\"max($2, $4, $6) / min($2, $4, $6)\")\n",
      "Thought: I can answer the question now.\n",
      "8. join()<END_OF_PLAN>\n",
      "###\n",
      "\n",
      "Question: Find a movie similar to Mission Impossible, The Silence of the Lambs, American Beauty, Star Wars Episode IV - A New Hope\n",
      "Options:\n",
      "Austin Powers International Man of Mystery\n",
      "Alesha Popvich and Tugarin the Dragon\n",
      "In Cold Blood\n",
      "Rosetta\n",
      "Thought: I need to find all movies in the Question.\n",
      "1. search(\"Mission Impossible\")\n",
      "2. search(\"The Silence of the Lambs\")\n",
      "3. search(\"American Beauty\")\n",
      "4. search(\"Star Wars Episode IV - A New Hope\")\n",
      "Thought: I need to find all movies in the Options.\n",
      "5. search(Austin Powers International Man of Mystery)\n",
      "6. search(Alesha Popvich and Tugarin the Dragon)\n",
      "7. search(In Cold Blood)\n",
      "8. search(Rosetta)\n",
      "Thought: I can answer the question now.\n",
      "9. join()<END_OF_PLAN>\n",
      "###\n",
      "\n",
      "Question: Which magazine was started first Arthur's Magazine or First for Women?\n",
      "1. search(\"Arthur's Magazine\")\n",
      "2. search(\"First for Women (magazine)\")\n",
      "Thought: I can answer the question now.\n",
      "3. join()<END_OF_PLAN>\n",
      "###\n",
      "\n",
      "Question: Were Pavel Urysohn and Leonid Levin known for the same type of work?\n",
      "1. search(\"Pavel Urysohn\")\n",
      "2. search(\"Leonid Levin\")\n",
      "Thought: I can answer the question now.\n",
      "3. join()<END_OF_PLAN>\n",
      "###\n",
      "\n",
      "Question: Determine the smaller value: the depth difference in meters between the Mariana Trench and the Puerto Rico Trench, or the depth difference in meters between the South Sandwich Trench and the Sunda Trench.\n",
      "1. search('Mariana Trench')\n",
      "2. search('Puerto Rico Trench')\n",
      "3. math('absolute depth difference between Mariana and Puerto Rico Trench in meters?', ['$1', '$2'])\n",
      "4. search('South Sandwich Trench')\n",
      "5. search('Sunda Trench')\n",
      "6. math('absolute depth difference between South Sandwich and Sunda Trench in meters?', ['$4', '$5'])\n",
      "7. math('min($3, $6)')\n",
      "Thought: I can answer the question now.\n",
      "8. join()<END_OF_PLAN>\n",
      "###\n",
      "\n",
      "Question: What is the raio of the height of Mount Everest and the height of Mount Kilimanjaro?\n",
      "1. search('Mount Everest')\n",
      "2. search('Mount Kilimanjaro')\n",
      "3. math('height of Mount Everest / height of Mount Kilimanjaro', ['$1', '$2'])\n",
      "Thought: I can answer the question now.\n",
      "4. join()<END_OF_PLAN>\n",
      "###\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent_worker = LLMCompilerAgentWorker.from_tools(\n",
    "    tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    callback_manager=callback_manager\n",
    ")\n",
    "agent = AgentRunner(agent_worker, callback_manager=callback_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0980a07-d2f5-434a-b9e9-80deabc0d1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step db4d859b-6ef4-4dd1-bd1e-6a2c42a0b4a8 for task d966bb3d-95c1-4396-a187-529d394faad0.\n",
      "> Step count: 0\n",
      "\u001b[1;3;38;5;200m> Plan: 1. multiply(121, 3)\n",
      "2. add($1, 42)\n",
      "3. join()<END_OF_PLAN>\n",
      "\u001b[0m\u001b[1;3;34mRan task: multiply. Observation: 363\n",
      "\u001b[0m\u001b[1;3;34mRan task: add. Observation: 405\n",
      "\u001b[0m\u001b[1;3;34mRan task: join. Observation: None\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What is (121 * 3) + 42?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ebe5e1f-4929-4f47-9af2-1da8faebe638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='405', sources=[], source_nodes=[])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6286e2b-16e7-4ff4-be6c-8dac4994bd47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2647c3be-1637-4b88-ae76-bb513f7e9682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
