{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebf73ae-a632-4d09-b941-6739e35b760d",
   "metadata": {},
   "source": [
    "# An Introduction to LlamaIndex Query Pipelines\n",
    "\n",
    "## Overview\n",
    "LlamaIndex provides a declarative query API that allows you to chain together different modules in order to orchestrate simple-to-advanced workflows over your data.\n",
    "\n",
    "This is centered around our `QueryPipeline` abstraction. Load in a variety of modules (from LLMs to prompts to retrievers to other pipelines), connect them all together into a sequential chain or DAG, and run it end2end.\n",
    "\n",
    "**NOTE**: You can orchestrate all these workflows without the declarative pipeline abstraction (by using the modules imperatively and writing your own functions). So what are the advantages of `QueryPipeline`? \n",
    "\n",
    "- Express common workflows with fewer lines of code/boilerplate\n",
    "- Greater readability\n",
    "- Greater parity / better integration points with common low-code / no-code solutions (e.g. LangFlow)\n",
    "- [In the future] A declarative interface allows easy serializability of pipeline components, providing portability of pipelines/easier deployment to different systems.\n",
    "\n",
    "## Cookbook\n",
    "\n",
    "In this cookbook we give you an introduction to our `QueryPipeline` interface and show you some basic workflows you can tackle.\n",
    "\n",
    "- Chain together prompt and LLM\n",
    "- Chain together query rewriting (prompt + LLM) with retrieval\n",
    "- Chain together a full RAG query pipeline (query rewriting, retrieval, reranking, response synthesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1144b2d4-adbc-44da-8c12-bdb5fe4b18bb",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Here we setup some data + indexes (from PG's essay) that we'll be using in the rest of the cookbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc82744-965a-4d79-b357-faf3de7ba2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup Arize Phoenix for logging/observability\n",
    "import phoenix as px\n",
    "px.launch_app()\n",
    "import llama_index\n",
    "llama_index.set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fcb621-0894-457e-b602-dbf5fb9134ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_pipeline.query import QueryPipeline\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.prompts import PromptTemplate\n",
    "from llama_index import (\n",
    "    VectorStoreIndex, \n",
    "    ServiceContext,\n",
    "    SimpleDirectoryReader,\n",
    "    load_index_from_storage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009af96-59e3-4d14-8272-382203c8b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(\"../data/paul_graham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d390b-38ca-4176-8cdb-8c2a0af1add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ddc81-0783-4fa5-ade0-60700c918011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.storage import StorageContext\n",
    "\n",
    "if not os.path.exists(\"storage\"):\n",
    "    index = VectorStoreIndex.from_documents(docs)\n",
    "    # save index to disk\n",
    "    index.set_index_id(\"vector_index\")\n",
    "    index.storage_context.persist(\"./storage\")\n",
    "else:\n",
    "    # rebuild storage context\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"storage\")\n",
    "    # load index\n",
    "    index = load_index_from_storage(storage_context, index_id=\"vector_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c59b5c-9b18-4dfa-97ef-e39b8069b73c",
   "metadata": {},
   "source": [
    "## 1. Chain Together Prompt and LLM \n",
    "\n",
    "In this section we show a super simple workflow of chaining together a prompt with LLM.\n",
    "\n",
    "We simply define `chain` on initialization. This is a special case of a query pipeline where the components are purely sequential, and we automatically convert outputs into the right format for the next inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb233a0f-2993-4780-a241-6a2299047598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try chaining basic prompts\n",
    "prompt_str = \"Please generate related movies to {movie_name}\"\n",
    "prompt_tmpl = PromptTemplate(prompt_str)\n",
    "llm = OpenAI(model='gpt-3.5-turbo')\n",
    "\n",
    "p = QueryPipeline(chain=[prompt_tmpl, llm], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b26c0c6-b886-42a6-b524-b19b18d1c01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module 754bbc40-f642-4522-b838-6ad07fc4bcfb with input: \n",
      "movie_name: The Departed\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module e76f2960-d545-4116-abc0-7baa2feba63c with input: \n",
      "messages: Please generate related movies to The Departed\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "output = p.run(movie_name=\"The Departed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d05cba-8e06-4c05-9bc7-38535814c066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: 1. Infernal Affairs (2002) - The Departed is actually a remake of this Hong Kong crime thriller. It follows a similar storyline of undercover cops infiltrating the criminal underworld.\n",
      "\n",
      "2. The Town (2010) - Directed by Ben Affleck, this crime drama revolves around a group of bank robbers in Boston. It explores themes of loyalty, betrayal, and the blurred lines between law enforcement and criminals.\n",
      "\n",
      "3. American Gangster (2007) - Based on a true story, this crime film follows the rise and fall of a Harlem drug lord and the detective determined to bring him down. It delves into the corrupt world of organized crime and the efforts to dismantle it.\n",
      "\n",
      "4. Training Day (2001) - Denzel Washington won an Academy Award for his portrayal of a corrupt narcotics detective in this intense crime thriller. It showcases the moral dilemmas faced by law enforcement officers and the consequences of their actions.\n",
      "\n",
      "5. The Departed (2006) - Although it's the same movie, it's worth mentioning it as a related film. Directed by Martin Scorsese, it explores the intertwining lives of an undercover cop and a mole in the police force, leading to a web of deception, violence, and betrayal.\n",
      "\n",
      "6. Donnie Brasco (1997) - Based on a true story, this crime drama follows an FBI agent who infiltrates the Mafia and forms a close bond with a low-level mobster. It delves into the complexities of undercover work and the toll it takes on personal relationships.\n",
      "\n",
      "7. Eastern Promises (2007) - Directed by David Cronenberg, this thriller revolves around a British midwife who becomes entangled with the Russian Mafia in London. It explores themes of loyalty, honor, and the consequences of crossing dangerous criminal organizations.\n",
      "\n",
      "8. The Godfather (1972) - Francis Ford Coppola's iconic crime saga follows the Corleone family, an organized crime dynasty, and their struggles for power and control. It is considered one of the greatest films of all time and explores similar themes of loyalty, betrayal, and the consequences of a life of crime.\n",
      "\n",
      "9. Heat (1995) - Directed by Michael Mann, this crime thriller showcases the cat-and-mouse game between a skilled detective and a professional thief. It delves into the psychological dynamics between law enforcement and criminals and the sacrifices made in pursuit of justice.\n",
      "\n",
      "10. Casino (1995) - Another Martin Scorsese film, this crime drama explores the dark underbelly of Las Vegas and the corrupting influence of money and power. It follows a casino executive's descent into criminal activities and the efforts of law enforcement to bring him down.\n"
     ]
    }
   ],
   "source": [
    "print(str(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4572cdd4-2c94-4871-a496-623e9779e0db",
   "metadata": {},
   "source": [
    "## Chain Together Query Rewriting Workflow (prompts + LLM) with Retrieval\n",
    "\n",
    "Here we try a slightly more complex workflow where we send the input through two prompts before initiating retrieval.\n",
    "\n",
    "1. Generate question about given topic.\n",
    "2. Hallucinate answer given question, for better retrieval.\n",
    "\n",
    "Since each prompt only takes in one input, note that the `QueryPipeline` will automatically chain LLM outputs into the prompt and then into the LLM. \n",
    "\n",
    "You'll see how to define links more explicitly in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6908b1-5819-4f34-a06c-2f8b9fc81c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor import CohereRerank\n",
    "\n",
    "# generate question regarding topic\n",
    "prompt_str1 = \"Please generate a concise question about Paul Graham's life regarding the following topic {topic}\"\n",
    "prompt_tmpl1 = PromptTemplate(prompt_str1)\n",
    "# use HyDE to hallucinate answer.\n",
    "prompt_str2 = (\n",
    "    \"Please write a passage to answer the question\\n\"\n",
    "    \"Try to include as many key details as possible.\\n\"\n",
    "    \"\\n\"\n",
    "    \"\\n\"\n",
    "    \"{query_str}\\n\"\n",
    "    \"\\n\"\n",
    "    \"\\n\"\n",
    "    'Passage:\"\"\"\\n'\n",
    ")\n",
    "prompt_tmpl2 = PromptTemplate(prompt_str2)\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo')\n",
    "retriever = index.as_retriever(similarity_top_k=5)\n",
    "p = QueryPipeline(chain=[prompt_tmpl1, llm, prompt_tmpl2, llm, retriever], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb2534-a69a-46fd-b539-84ae93e2e5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module dcc5c91e-7e3e-4bf8-93e5-fb79b7b3f753 with input: \n",
      "topic: college\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module d3657f37-4e8b-45e7-a31c-a18b47f379b0 with input: \n",
      "messages: Please generate a concise question about Paul Graham's life regarding the following topic college\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module 5a961f21-b76b-47ae-a517-7227f852a2b3 with input: \n",
      "query_str: assistant: How did Paul Graham's college experience shape his career and entrepreneurial mindset?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module 453dabbc-8a39-44a0-bfed-3a8027159765 with input: \n",
      "messages: Please write a passage to answer the question\n",
      "Try to include as many key details as possible.\n",
      "\n",
      "\n",
      "assistant: How did Paul Graham's college experience shape his career and entrepreneurial mindset?\n",
      "\n",
      "\n",
      "Pass\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module f543ff83-c185-4a71-9aa7-96bfec15e403 with input: \n",
      "input: assistant: Paul Graham's college experience played a pivotal role in shaping his career trajectory and entrepreneurial mindset. As a student at Cornell University, Graham immersed himself in the world\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = p.run(topic=\"college\")\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c073634-55d4-4066-977f-fbc189089b95",
   "metadata": {},
   "source": [
    "## Chain Together a Full RAG Pipeline\n",
    "\n",
    "Here we chain together a full RAG pipeline consisting of query rewriting, retrieval, reranking, and response synthesis.\n",
    "\n",
    "Here we can't use `chain` syntax because certain modules depend on multiple inputs (for instance, response synthesis expects both the retrieved nodes and the original question). Instead we'll construct a DAG explicitly, through `add_modules` and then `add_link`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531677b6-0e6a-4002-9fdd-2096f1a83685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor import CohereRerank\n",
    "from llama_index.response_synthesizers import TreeSummarize\n",
    "from llama_index import ServiceContext\n",
    "\n",
    "# define modules\n",
    "prompt_str = \"Please generate a question about Paul Graham's life regarding the following topic {topic}\"\n",
    "prompt_tmpl = PromptTemplate(prompt_str)\n",
    "llm = OpenAI(model='gpt-3.5-turbo')\n",
    "retriever = index.as_retriever(similarity_top_k=3)\n",
    "reranker = CohereRerank()\n",
    "summarizer = TreeSummarize(service_context=ServiceContext.from_defaults(llm=llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30dddf-7768-4556-ae27-10251de2d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define query pipeline\n",
    "p = QueryPipeline(verbose=True)\n",
    "p.add_modules({\n",
    "\t\"llm\": llm,\n",
    "\t\"prompt_tmpl\": prompt_tmpl,\n",
    "\t\"retriever\": retriever,\n",
    "    \"summarizer\": summarizer,\n",
    "    \"reranker\": reranker\n",
    "})\n",
    "p.add_link(\"prompt_tmpl\", \"llm\")\n",
    "p.add_link(\"llm\", \"retriever\")\n",
    "p.add_link(\"retriever\", \"reranker\", dest_key=\"nodes\")\n",
    "p.add_link(\"llm\", \"reranker\", dest_key=\"query_str\")\n",
    "p.add_link(\"reranker\", \"summarizer\", dest_key=\"nodes\")\n",
    "p.add_link(\"llm\", \"summarizer\", dest_key=\"query_str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574ea13f-88e2-4393-8bd3-97fe436ffc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module prompt_tmpl with input: \n",
      "topic: YC\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm with input: \n",
      "messages: Please generate a question about Paul Graham's life regarding the following topic YC\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module retriever with input: \n",
      "input: assistant: What role did Paul Graham play in the founding and development of Y Combinator (YC)?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module reranker with input: \n",
      "query_str: assistant: What role did Paul Graham play in the founding and development of Y Combinator (YC)?\n",
      "nodes: [NodeWithScore(node=TextNode(id_='543f958b-2c46-4c0f-b046-22e0a60ea950', embedding=None, metadata={'file_path': '../data/paul_graham/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module summarizer with input: \n",
      "query_str: assistant: What role did Paul Graham play in the founding and development of Y Combinator (YC)?\n",
      "nodes: [NodeWithScore(node=TextNode(id_='6b43fef2-821a-49a2-a043-9d816b70560f', embedding=None, metadata={'file_path': '../data/paul_graham/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = p.run(topic=\"YC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a69cd4-f307-49a1-842c-bcf729715a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham played a significant role in the founding and development of Y Combinator (YC). He was one of the co-founders of YC and was actively involved in its early stages. He helped establish the Summer Founders Program (SFP) and was responsible for selecting and funding the initial batch of startups. Graham also played a key role in shaping the funding model for YC, based on previous deals and agreements. As YC grew, Graham's involvement expanded, and he dedicated a significant amount of his time and attention to the organization. However, in later years, he decided to step back from his role and hand over the leadership to Sam Altman.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
