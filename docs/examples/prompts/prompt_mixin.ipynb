{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a5a641c-d90c-4401-ad59-369d70babf5b",
   "metadata": {},
   "source": [
    "# WIP: make this way more detailed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487c01b6-60ea-457f-8cc9-2a448d401d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a94148e-a2f9-44b3-919f-4d9811ae27c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352384e6-0f31-4aa9-a351-4d3b278e2afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    load_index_from_storage,\n",
    "    StorageContext,\n",
    ")\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f1a04a-7859-4d97-810d-abde72891d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\n",
    "    \"../../../examples/paul_graham_essay/data\"\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84c7e74-c084-40b0-b94b-d454e095e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75b8534b-eb16-47a7-9269-dfd4ebf97fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine(response_mode=\"tree_summarize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f28b46d-6115-4095-b1a2-5603a8ee709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_dict = query_engine.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28d61d36-b2b6-4d04-8284-4004c1004966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary_template': 'Context information from multiple sources is below.\\n---------------------\\n{context_str}\\n---------------------\\nGiven the information from multiple sources and not prior knowledge, answer the query.\\nQuery: {query_str}\\nAnswer: '}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display({k: p.get_template() for k, p in prompts_dict.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4936c416-bdd8-48d4-95c3-760b5f2a2bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author worked on writing and programming outside of school before college. They wrote short stories and tried writing programs on an IBM 1401 computer using an early version of Fortran. They also mentioned getting a microcomputer, specifically a TRS-80, and started programming on it.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24621f9d-eea0-49bd-82d8-9433c14ce331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1545df36-4bd5-40d3-b4c8-a01c89774262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.prompts import PromptTemplate\n",
    "\n",
    "# shakespeare! \n",
    "new_summary_tmpl_str = (\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the query in the style of a Shakespeare play.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "new_summary_tmpl = PromptTemplate(new_summary_tmpl_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7687b-bdbf-454e-b3b3-4438b80934a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine.update_prompts(summary_template=new_summary_tmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad924fca-5074-4a04-99bc-e5dc0102d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_dict = query_engine.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc9e39a0-6db1-419f-816e-c702a8e49e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary_template': 'Context information is below.\\n---------------------\\n{context_str}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query in the style of a Shakespeare play.\\nQuery: {query_str}\\nAnswer: '}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display({k: p.get_template() for k, p in prompts_dict.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b195c32-1913-4d1a-b6cf-3f2635e8773a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In his youth, ere college days did commence,\n",
      "The author toiled on two pursuits intense.\n",
      "The first, a writer he did aspire to be,\n",
      "Crafting tales of characters, though not with glee.\n",
      "Short stories, lacking plot, did he create,\n",
      "Thinking them deep, with feelings strong, innate.\n",
      "\n",
      "But programming, too, did captivate his mind,\n",
      "With IBM 1401, a machine he did find.\n",
      "In the basement of his school, a lair so grand,\n",
      "With alien machines, a sight so grand.\n",
      "Fortran, the language, he did employ,\n",
      "Punch cards and printers, his tools of joy.\n",
      "\n",
      "Yet puzzled was he, with the 1401's might,\n",
      "No data stored, no input in sight.\n",
      "Calculating pi, a task he could not pursue,\n",
      "For math knowledge lacked, his options few.\n",
      "No programs of note, he could recall,\n",
      "Save for one that didn't terminate at all.\n",
      "\n",
      "Microcomputers, a revolution profound,\n",
      "Changed the game, a new world to be found.\n",
      "A friend built one, a kit from Heathkit's store,\n",
      "Envy and awe, the author's heart did soar.\n",
      "Years of nagging, his father did relent,\n",
      "A TRS-80, a computer heaven-sent.\n",
      "\n",
      "With this machine, his programming took flight,\n",
      "Simple games and rocket predictions, a delight.\n",
      "A word processor, limited in space,\n",
      "But better than a typewriter's embrace.\n",
      "Though college called, philosophy his aim,\n",
      "Boredom in those courses, a feeling untamed.\n",
      "\n",
      "AI, the field that beckoned him so,\n",
      "Inspired by Heinlein's novel's glow.\n",
      "\"The Moon is a Harsh Mistress,\" a tale so grand,\n",
      "With an intelligent computer, Mike, at hand.\n",
      "PBS showed Winograd and SHRDLU's might,\n",
      "Teaching it more words, a future bright.\n",
      "\n",
      "And then, a revelation, a moment of awe,\n",
      "The web's potential, a sight he saw.\n",
      "Publishing essays, a medium new,\n",
      "Accessible to all, a dream come true.\n",
      "In the print era, a narrow channel to fame,\n",
      "But now, anyone could publish, a change in the game.\n",
      "\n",
      "Essays, a form of expression long suppressed,\n",
      "Now had a platform, a chance to impress.\n",
      "Unprestigious work, a path he chose,\n",
      "To discover truths, where few would go.\n",
      "Writing essays, a passion he'd always keep,\n",
      "A sign of motives pure, away from the deep.\n",
      "\n",
      "Years passed, essays written, a collection amassed,\n",
      "O'Reilly published them, a book unsurpassed.\n",
      "Spam filters and painting, endeavors diverse,\n",
      "Thursday night dinners, cooking for a universe.\n",
      "A building in Cambridge, an office to reside,\n",
      "Once a candy factory, with secrets to hide.\n",
      "\n",
      "Then fate intervened, a party so grand,\n",
      "A woman named Jessica, fate's guiding hand.\n",
      "A marketing maven, from a bank she came,\n",
      "But startups' reality, not quite the same.\n",
      "Inspired by their stories, she sought to compile,\n",
      "A book of interviews, startup founders' style.\n",
      "\n",
      "As the bank faltered, and staff were let go,\n",
      "Jessica sought new opportunities to sow.\n",
      "A marketing job at a VC firm she did seek,\n",
      "But during the wait, the author did speak.\n",
      "Of the flaws in venture capital, he did share,\n",
      "A conversation that would lead to a pair.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa208b5e-6453-43c9-aea3-3907aef760df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
