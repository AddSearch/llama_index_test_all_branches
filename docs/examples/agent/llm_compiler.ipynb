{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2cf3ee9-d4dd-44d1-a529-6e92d9f8e023",
   "metadata": {},
   "source": [
    "# LLM Compiler Agent\n",
    "\n",
    "Full credits to the [source repo for LLMCompiler](https://github.com/SqueezeAILab/LLMCompiler).\n",
    "\n",
    "A lot of our implementation was lifted from this repo (and adapted with LlamaIndex modules).\n",
    "\n",
    "LLM Compiler agent notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "338345d0-0b03-44f0-b812-d98b530d047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6fdf3ad-0ded-4165-bdc6-870f91dc723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Sequence, List\n",
    "\n",
    "from llama_index.llms import OpenAI, ChatMessage\n",
    "from llama_index.tools import BaseTool, FunctionTool\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13da398-bd9e-4f2e-82d2-2dbb62a3ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "\n",
    "tools = [multiply_tool, add_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd19c91f-af44-4032-a9c5-50512f3c66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import AgentRunner\n",
    "from llama_index.agent.llm_compiler.step import LLMCompilerAgentWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eedb5565-7cfe-4d81-9c04-91a84a3f76af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: Given a user query, create a plan to solve it with the utmost parallelizability. Each plan should comprise an action from the following 3 types:\n",
      "1. multiply(a: int, b: int) -> int\n",
      "Multiple two integers and returns the result integer\n",
      "2. add(a: int, b: int) -> int\n",
      "Add two integers and returns the result integer\n",
      "3. join():\n",
      " - Collects and combines results from prior actions.\n",
      " - A LLM agent is called upon invoking join to either finalize the user query or wait until the plans are executed.\n",
      " - join should always be the last action in the plan, and will be called in two scenarios:\n",
      "   (a) if the answer can be determined by gathering the outputs from tasks to generate the final response.\n",
      "   (b) if the answer cannot be determined in the planning phase before you execute the plans. \n",
      "\n",
      "Guidelines:\n",
      " - Each action described above contains input/output types and description.\n",
      "    - You must strictly adhere to the input and output types for each action.\n",
      "    - The action descriptions contain the guidelines. You MUST strictly follow those guidelines when you use the actions.\n",
      " - Each action in the plan should strictly be one of the above types. Follow the Python conventions for each action.\n",
      " - Each action MUST have a unique ID, which is strictly increasing.\n",
      " - Inputs for actions can either be constants or outputs from preceding actions. In the latter case, use the format $id to denote the ID of the previous action whose output will be the input.\n",
      " - Always call join as the last action in the plan. Say '<END_OF_PLAN>' after you call join\n",
      " - Ensure the plan maximizes parallelizability.\n",
      " - Only use the provided action types. If a query cannot be addressed using these, invoke the join action for the next steps.\n",
      " - Never explain the plan with comments (e.g. #).\n",
      " - Never introduce new actions other than the ones provided.\n",
      "\n",
      "\n",
      "PREFIX: Given a user query, create a plan to solve it with the utmost parallelizability. Each plan should comprise an action from the following 3 types:\n",
      "1. multiply(a: int, b: int) -> int\n",
      "Multiple two integers and returns the result integer\n",
      "2. add(a: int, b: int) -> int\n",
      "Add two integers and returns the result integer\n",
      "3. join():\n",
      " - Collects and combines results from prior actions.\n",
      " - A LLM agent is called upon invoking join to either finalize the user query or wait until the plans are executed.\n",
      " - join should always be the last action in the plan, and will be called in two scenarios:\n",
      "   (a) if the answer can be determined by gathering the outputs from tasks to generate the final response.\n",
      "   (b) if the answer cannot be determined in the planning phase before you execute the plans. \n",
      "\n",
      "Guidelines:\n",
      " - Each action described above contains input/output types and description.\n",
      "    - You must strictly adhere to the input and output types for each action.\n",
      "    - The action descriptions contain the guidelines. You MUST strictly follow those guidelines when you use the actions.\n",
      " - Each action in the plan should strictly be one of the above types. Follow the Python conventions for each action.\n",
      " - Each action MUST have a unique ID, which is strictly increasing.\n",
      " - Inputs for actions can either be constants or outputs from preceding actions. In the latter case, use the format $id to denote the ID of the previous action whose output will be the input.\n",
      " - Always call join as the last action in the plan. Say '<END_OF_PLAN>' after you call join\n",
      " - Ensure the plan maximizes parallelizability.\n",
      " - Only use the provided action types. If a query cannot be addressed using these, invoke the join action for the next steps.\n",
      " - Never explain the plan with comments (e.g. #).\n",
      " - Never introduce new actions other than the ones provided.\n",
      "\n",
      " - You are given \"Previous Plan\" which is the plan that the previous agent created along with the execution results (given as Observation) of each plan and a general thought (given as Thought) about the executed results.You MUST use these information to create the next plan under \"Current Plan\".\n",
      " - When starting the Current Plan, you should start with \"Thought\" that outlines the strategy for the next plan.\n",
      " - In the Current Plan, you should NEVER repeat the actions that are already executed in the Previous Plan.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent_worker = LLMCompilerAgentWorker.from_tools(\n",
    "    tools,\n",
    "    llm=OpenAI(model=\"gpt-4\")\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0980a07-d2f5-434a-b9e9-80deabc0d1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text Plan:\n",
      "1. multiply(121, 3) -> 363\n",
      "2. add($1, 42) -> 405\n",
      "3. join()\n",
      "<END_OF_PLAN>\n",
      "matches [('', '1', 'multiply', '121, 3', ''), ('', '2', 'add', '$1, 42', ''), ('', '3', 'join', '', '')]\n",
      "results [LLMCompilerParseResult(thought='', idx=1, tool_name='multiply', args='121, 3'), LLMCompilerParseResult(thought='', idx=2, tool_name='add', args='$1, 42'), LLMCompilerParseResult(thought='', idx=3, tool_name='join', args='')]\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What is (121 * 3) + 42?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebe5e1f-4929-4f47-9af2-1da8faebe638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='405', sources=[], source_nodes=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6286e2b-16e7-4ff4-be6c-8dac4994bd47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2647c3be-1637-4b88-ae76-bb513f7e9682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
